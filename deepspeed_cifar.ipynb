{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate azureml_py38_PT_TF\n",
        "pip install deepspeed\n",
        "pip install mpi4py\n",
        "pip install ipywidgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: deepspeed in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.5.10)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.21.5)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (21.3)\nRequirement already satisfied: hjson in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (3.0.2)\nRequirement already satisfied: py-cpuinfo in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (8.0.0)\nRequirement already satisfied: triton==1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.0.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (4.62.3)\nRequirement already satisfied: ninja in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.10.2.3)\nRequirement already satisfied: psutil in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (5.9.0)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.10.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging->deepspeed) (3.0.6)\nRequirement already satisfied: typing_extensions in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torch->deepspeed) (4.0.1)\nRequirement already satisfied: mpi4py in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (3.1.3)\nRequirement already satisfied: ipywidgets in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (7.6.5)\nRequirement already satisfied: traitlets>=4.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\nRequirement already satisfied: nbformat>=4.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\nRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (7.30.1)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (6.6.0)\nRequirement already satisfied: jupyter-core in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\nRequirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.24)\nRequirement already satisfied: pygments in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.11.0)\nRequirement already satisfied: matplotlib-inline in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.3)\nRequirement already satisfied: decorator in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (5.1.0)\nRequirement already satisfied: backcall in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (50.3.0.post20201006)\nRequirement already satisfied: pickleshare in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\nRequirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\nRequirement already satisfied: notebook>=4.4.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\nRequirement already satisfied: tornado<7.0,>=4.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\nRequirement already satisfied: jupyter-client<8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.0)\nRequirement already satisfied: debugpy<2.0,>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\nRequirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\nRequirement already satisfied: wcwidth in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\nRequirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\nRequirement already satisfied: terminado>=0.8.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\nRequirement already satisfied: argon2-cffi in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\nRequirement already satisfied: nbconvert in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.1)\nRequirement already satisfied: nest-asyncio>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.4)\nRequirement already satisfied: pyzmq>=17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\nRequirement already satisfied: prometheus-client in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.0)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\nRequirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\nRequirement already satisfied: entrypoints in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\nRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\nRequirement already satisfied: defusedxml in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.10)\nRequirement already satisfied: bleach in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\nRequirement already satisfied: mistune<2,>=0.8.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\nRequirement already satisfied: testpath in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\nRequirement already satisfied: cffi>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\nRequirement already satisfied: webencodings in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.6)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup an experiment to log metrics\n",
        "from azureml.core import Workspace\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "\n",
        "mlflow.create_experiment(\"deepspeed-notebook\")\n",
        "mlflow.set_experiment(\"deepspeed-notebook\")\n",
        "mlflow_run = mlflow.start_run()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543789212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import deepspeed\n",
        "\n",
        "#initialize deepspeed to get process rank below\n",
        "deepspeed.init_distributed()\n",
        "\n",
        "\n",
        "#load and prepare the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "if torch.distributed.get_rank() != 0:\n",
        "    # might be downloading cifar data, let rank 0 download first\n",
        "    torch.distributed.barrier()\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "\n",
        "if torch.distributed.get_rank() == 0:\n",
        "    # cifar data is downloaded, indicate other ranks can proceed\n",
        "    torch.distributed.barrier()\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=16,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=4,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-11 01:43:11,179] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...\n[2022-02-11 01:43:13,558] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.0.0.5, master_port=29500\n[2022-02-11 01:43:13,559] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl\nFiles already downloaded and verified\nFiles already downloaded and verified\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1644543880755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_config = {\n",
        "  \"train_batch_size\": 16,\n",
        "  \"steps_per_print\": 2000,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"Adam\",\n",
        "    \"params\": {\n",
        "      \"lr\": 0.001,\n",
        "      \"betas\": [\n",
        "        0.8,\n",
        "        0.999\n",
        "      ],\n",
        "      \"eps\": 1e-8,\n",
        "      \"weight_decay\": 3e-7\n",
        "    }\n",
        "  },\n",
        "  \"scheduler\": {\n",
        "    \"type\": \"WarmupLR\",\n",
        "    \"params\": {\n",
        "      \"warmup_min_lr\": 0,\n",
        "      \"warmup_max_lr\": 0.001,\n",
        "      \"warmup_num_steps\": 1000\n",
        "    }\n",
        "  },\n",
        "  \"gradient_clipping\": 1.0,\n",
        "  \"prescale_gradients\": False,\n",
        "  \"fp16\": {\n",
        "      \"enabled\": True,\n",
        "      \"fp16_master_weights_and_grads\": False,\n",
        "      \"loss_scale\": 0,\n",
        "      \"loss_scale_window\": 500,\n",
        "      \"hysteresis\": 2,\n",
        "      \"min_loss_scale\": 1,\n",
        "      \"initial_scale_power\": 15\n",
        "  },\n",
        "  \"wall_clock_breakdown\": False,\n",
        "  \"zero_optimization\": {\n",
        "      \"stage\": 0,\n",
        "      \"allgather_partitions\": True,\n",
        "      \"reduce_scatter\": True,\n",
        "      \"allgather_bucket_size\": 50000000,\n",
        "      \"reduce_bucket_size\": 50000000,\n",
        "      \"overlap_comm\": True,\n",
        "      \"contiguous_gradients\": True,\n",
        "      \"cpu_offload\": False\n",
        "  }\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543880900
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='CIFAR')\n",
        "\n",
        "parser.add_argument('--with_cuda',\n",
        "                    default=True,\n",
        "                    action='store_true',\n",
        "                    help='use CPU in case there\\'s no GPU support')\n",
        "\n",
        "parser.add_argument('--use_ema',\n",
        "                    default=False,\n",
        "                    action='store_true',\n",
        "                    help='whether use exponential moving average')\n",
        "\n",
        "parser.add_argument('-e',\n",
        "                    '--epochs',\n",
        "                    default=30,\n",
        "                    type=int,\n",
        "                    help='number of total epochs (default: 30)')\n",
        "\n",
        "parser.add_argument('--local_rank',\n",
        "                    type=int,\n",
        "                    default=-1,\n",
        "                    help='local rank passed from distributed launcher')\n",
        "\n",
        "parser.add_argument('--log-interval',\n",
        "                    type=int,\n",
        "                    default=500,\n",
        "                    help=\"output logging information at a given interval\")\n",
        "\n",
        "\n",
        "parser.add_argument('--ep-world-size',\n",
        "                    default=4,\n",
        "                    type=int,\n",
        "                    help='(moe) expert parallel world size')\n",
        "parser.add_argument('--num-experts',\n",
        "                    default=8,\n",
        "                    type=int,\n",
        "                    help='(moe) number of total experts')\n",
        "\n",
        "parser.add_argument('--top-k',\n",
        "                    default=1,\n",
        "                    type=int,\n",
        "                    help='(moe) gating top 1 and 2 supported')\n",
        "\n",
        "parser.add_argument('--min-capacity',\n",
        "                    default=0,\n",
        "                    type=int,\n",
        "                    help='(moe) minimum capacity of an expert regardless of the capacity_factor')\n",
        "\n",
        "parser.add_argument(\n",
        "                '--noisy-gate-policy',\n",
        "                default=None,\n",
        "                type=str,\n",
        "                help='(moe) noisy gating (only supported with top-1). Valid values are None, RSample, and Jitter')\n",
        "\n",
        "parser.add_argument(\n",
        "                '--moe-param-group',\n",
        "                default=False,\n",
        "                action='store_true',\n",
        "                help='(moe) create separate moe param groups, required when using ZeRO w. MoE')\n",
        "\n",
        "# Include DeepSpeed configuration arguments\n",
        "parser = deepspeed.add_config_arguments(parser)\n",
        "\n",
        "args = parser.parse_args(\"\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543881032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.log_param(\"ema\", args.use_ema)\n",
        "mlflow.log_param(\"epochs\", args.epochs)\n",
        "mlflow.log_param(\"experts\", args.num_experts)\n",
        "mlflow.log_param(\"noisy gate\", args.noisy_gate_policy)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543881299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepspeed.utils.groups.initialize(ep_size=args.ep_world_size)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-11 01:44:42,211] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed groups\n[2022-02-11 01:44:42,212] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n[2022-02-11 01:44:42,215] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 4\n[2022-02-11 01:44:42,216] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]\n[2022-02-11 01:44:42,217] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543881399
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 84)\n",
        "        self.fc3 = deepspeed.moe.layer.MoE(\n",
        "            hidden_size=84,\n",
        "            expert=self.fc3,\n",
        "            num_experts=args.num_experts,\n",
        "            k=args.top_k,\n",
        "            min_capacity=args.min_capacity,\n",
        "            noisy_gate_policy=args.noisy_gate_policy)\n",
        "        self.fc4 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x, gate_loss, _ = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x , gate_loss\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "\n",
        "def create_moe_param_groups(model):\n",
        "    from deepspeed.moe.utils import split_params_into_different_moe_groups_for_optimizer\n",
        "\n",
        "    parameters = {'params': model.parameters(), 'name': 'parameters'}\n",
        "\n",
        "    return split_params_into_different_moe_groups_for_optimizer(parameters)\n",
        "\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "if args.moe_param_group:\n",
        "    parameters = create_moe_param_groups(net)\n",
        "\n",
        "#initialize Deepspeed\n",
        "model_engine, optimizer, trainloader, __ = deepspeed.initialize(\n",
        "    args=args, model=net, model_parameters=parameters, training_data=trainset, config=ds_config)\n",
        "\n",
        "fp16 = model_engine.fp16_enabled()\n",
        "print(f'fp16={fp16}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-11 01:44:42,466] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 8 | num_local_experts: 8 | expert_parallel_size: 1\n[2022-02-11 01:44:42,604] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.5.10, git-hash=unknown, git-branch=unknown\n[2022-02-11 01:44:42,740] [INFO] [engine.py:275:__init__] DeepSpeed Flops Profiler Enabled: False\nInstalled CUDA version 11.2 does not match the version torch was compiled with 11.1 but since the APIs are compatible, accepting this combination\nUsing /home/azureuser/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /home/azureuser/.cache/torch_extensions/py38_cu111/fused_adam/build.ninja...\nBuilding extension module fused_adam...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module fused_adam...\nTime to load fused_adam op: 0.4612245559692383 seconds\n[2022-02-11 01:44:43,938] [INFO] [engine.py:1105:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n[2022-02-11 01:44:43,940] [INFO] [engine.py:1113:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n[2022-02-11 01:44:43,940] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n[2022-02-11 01:44:44,048] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n[2022-02-11 01:44:44,049] [INFO] [engine.py:795:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n[2022-02-11 01:44:44,050] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f059413c580>\n[2022-02-11 01:44:44,050] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n[2022-02-11 01:44:44,051] [INFO] [config.py:1058:print] DeepSpeedEngine configuration:\n[2022-02-11 01:44:44,052] [INFO] [config.py:1062:print]   activation_checkpointing_config  {\n    \"partition_activations\": false, \n    \"contiguous_memory_optimization\": false, \n    \"cpu_checkpointing\": false, \n    \"number_checkpoints\": null, \n    \"synchronize_checkpoint_boundary\": false, \n    \"profile\": false\n}\n[2022-02-11 01:44:44,053] [INFO] [config.py:1062:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n[2022-02-11 01:44:44,053] [INFO] [config.py:1062:print]   amp_enabled .................. False\n[2022-02-11 01:44:44,054] [INFO] [config.py:1062:print]   amp_params ................... False\n[2022-02-11 01:44:44,055] [INFO] [config.py:1062:print]   autotuning_config ............ {\n    \"enabled\": false, \n    \"start_step\": null, \n    \"end_step\": null, \n    \"metric_path\": null, \n    \"arg_mappings\": null, \n    \"metric\": \"throughput\", \n    \"model_info\": null, \n    \"results_dir\": null, \n    \"exps_dir\": null, \n    \"overwrite\": true, \n    \"fast\": true, \n    \"start_profile_step\": 3, \n    \"end_profile_step\": 5, \n    \"tuner_type\": \"gridsearch\", \n    \"tuner_early_stopping\": 5, \n    \"tuner_num_trials\": 50, \n    \"model_info_path\": null, \n    \"mp_size\": 1, \n    \"max_train_batch_size\": null, \n    \"min_train_batch_size\": 1, \n    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n    \"min_train_micro_batch_size_per_gpu\": 1, \n    \"num_tuning_micro_batch_sizes\": 3\n}\n[2022-02-11 01:44:44,055] [INFO] [config.py:1062:print]   bfloat16_enabled ............. False\n[2022-02-11 01:44:44,056] [INFO] [config.py:1062:print]   checkpoint_tag_validation_enabled  True\n[2022-02-11 01:44:44,056] [INFO] [config.py:1062:print]   checkpoint_tag_validation_fail  False\n[2022-02-11 01:44:44,057] [INFO] [config.py:1062:print]   communication_data_type ...... None\n[2022-02-11 01:44:44,059] [INFO] [config.py:1062:print]   curriculum_enabled ........... False\n[2022-02-11 01:44:44,059] [INFO] [config.py:1062:print]   curriculum_params ............ False\n[2022-02-11 01:44:44,060] [INFO] [config.py:1062:print]   dataloader_drop_last ......... False\n[2022-02-11 01:44:44,060] [INFO] [config.py:1062:print]   disable_allgather ............ False\n[2022-02-11 01:44:44,061] [INFO] [config.py:1062:print]   dump_state ................... False\n[2022-02-11 01:44:44,062] [INFO] [config.py:1062:print]   dynamic_loss_scale_args ...... {'init_scale': 32768, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}\n[2022-02-11 01:44:44,062] [INFO] [config.py:1062:print]   eigenvalue_enabled ........... False\n[2022-02-11 01:44:44,062] [INFO] [config.py:1062:print]   eigenvalue_gas_boundary_resolution  1\n[2022-02-11 01:44:44,063] [INFO] [config.py:1062:print]   eigenvalue_layer_name ........ bert.encoder.layer\n[2022-02-11 01:44:44,064] [INFO] [config.py:1062:print]   eigenvalue_layer_num ......... 0\n[2022-02-11 01:44:44,064] [INFO] [config.py:1062:print]   eigenvalue_max_iter .......... 100\n[2022-02-11 01:44:44,065] [INFO] [config.py:1062:print]   eigenvalue_stability ......... 1e-06\n[2022-02-11 01:44:44,066] [INFO] [config.py:1062:print]   eigenvalue_tol ............... 0.01\n[2022-02-11 01:44:44,066] [INFO] [config.py:1062:print]   eigenvalue_verbose ........... False\n[2022-02-11 01:44:44,066] [INFO] [config.py:1062:print]   elasticity_enabled ........... False\n[2022-02-11 01:44:44,067] [INFO] [config.py:1062:print]   flops_profiler_config ........ {\n    \"enabled\": false, \n    \"profile_step\": 1, \n    \"module_depth\": -1, \n    \"top_modules\": 1, \n    \"detailed\": true, \n    \"output_file\": null\n}\n[2022-02-11 01:44:44,067] [INFO] [config.py:1062:print]   fp16_enabled ................. True\n[2022-02-11 01:44:44,068] [INFO] [config.py:1062:print]   fp16_master_weights_and_gradients  False\n[2022-02-11 01:44:44,068] [INFO] [config.py:1062:print]   fp16_mixed_quantize .......... False\n[2022-02-11 01:44:44,069] [INFO] [config.py:1062:print]   global_rank .................. 0\n[2022-02-11 01:44:44,069] [INFO] [config.py:1062:print]   gradient_accumulation_steps .. 1\n[2022-02-11 01:44:44,069] [INFO] [config.py:1062:print]   gradient_clipping ............ 1.0\n[2022-02-11 01:44:44,070] [INFO] [config.py:1062:print]   gradient_predivide_factor .... 1.0\n[2022-02-11 01:44:44,070] [INFO] [config.py:1062:print]   initial_dynamic_scale ........ 32768\n[2022-02-11 01:44:44,071] [INFO] [config.py:1062:print]   loss_scale ................... 0\n[2022-02-11 01:44:44,071] [INFO] [config.py:1062:print]   memory_breakdown ............. False\n[2022-02-11 01:44:44,072] [INFO] [config.py:1062:print]   optimizer_legacy_fusion ...... False\n[2022-02-11 01:44:44,073] [INFO] [config.py:1062:print]   optimizer_name ............... adam\n[2022-02-11 01:44:44,073] [INFO] [config.py:1062:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n[2022-02-11 01:44:44,074] [INFO] [config.py:1062:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n[2022-02-11 01:44:44,074] [INFO] [config.py:1062:print]   pld_enabled .................. False\n[2022-02-11 01:44:44,074] [INFO] [config.py:1062:print]   pld_params ................... False\n[2022-02-11 01:44:44,075] [INFO] [config.py:1062:print]   prescale_gradients ........... False\n[2022-02-11 01:44:44,075] [INFO] [config.py:1062:print]   quantize_change_rate ......... 0.001\n[2022-02-11 01:44:44,076] [INFO] [config.py:1062:print]   quantize_groups .............. 1\n[2022-02-11 01:44:44,076] [INFO] [config.py:1062:print]   quantize_offset .............. 1000\n[2022-02-11 01:44:44,077] [INFO] [config.py:1062:print]   quantize_period .............. 1000\n[2022-02-11 01:44:44,077] [INFO] [config.py:1062:print]   quantize_rounding ............ 0\n[2022-02-11 01:44:44,078] [INFO] [config.py:1062:print]   quantize_start_bits .......... 16\n[2022-02-11 01:44:44,078] [INFO] [config.py:1062:print]   quantize_target_bits ......... 8\n[2022-02-11 01:44:44,079] [INFO] [config.py:1062:print]   quantize_training_enabled .... False\n[2022-02-11 01:44:44,083] [INFO] [config.py:1062:print]   quantize_type ................ 0\n[2022-02-11 01:44:44,083] [INFO] [config.py:1062:print]   quantize_verbose ............. False\n[2022-02-11 01:44:44,083] [INFO] [config.py:1062:print]   scheduler_name ............... WarmupLR\n[2022-02-11 01:44:44,084] [INFO] [config.py:1062:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n[2022-02-11 01:44:44,084] [INFO] [config.py:1062:print]   sparse_attention ............. None\n[2022-02-11 01:44:44,085] [INFO] [config.py:1062:print]   sparse_gradients_enabled ..... False\n[2022-02-11 01:44:44,085] [INFO] [config.py:1062:print]   steps_per_print .............. 2000\n[2022-02-11 01:44:44,086] [INFO] [config.py:1062:print]   tensorboard_enabled .......... False\n[2022-02-11 01:44:44,086] [INFO] [config.py:1062:print]   tensorboard_job_name ......... DeepSpeedJobName\n[2022-02-11 01:44:44,087] [INFO] [config.py:1062:print]   tensorboard_output_path ...... \n[2022-02-11 01:44:44,087] [INFO] [config.py:1062:print]   train_batch_size ............. 16\n[2022-02-11 01:44:44,087] [INFO] [config.py:1062:print]   train_micro_batch_size_per_gpu  16\n[2022-02-11 01:44:44,088] [INFO] [config.py:1062:print]   use_quantizer_kernel ......... False\n[2022-02-11 01:44:44,088] [INFO] [config.py:1062:print]   wall_clock_breakdown ......... False\n[2022-02-11 01:44:44,089] [INFO] [config.py:1062:print]   world_size ................... 1\n[2022-02-11 01:44:44,089] [INFO] [config.py:1062:print]   zero_allow_untested_optimizer  False\n[2022-02-11 01:44:44,090] [INFO] [config.py:1062:print]   zero_config .................. {\n    \"stage\": 0, \n    \"contiguous_gradients\": true, \n    \"reduce_scatter\": true, \n    \"reduce_bucket_size\": 5.000000e+07, \n    \"allgather_partitions\": true, \n    \"allgather_bucket_size\": 5.000000e+07, \n    \"overlap_comm\": true, \n    \"load_from_fp32_weights\": true, \n    \"elastic_checkpoint\": false, \n    \"offload_param\": null, \n    \"offload_optimizer\": null, \n    \"sub_group_size\": 1.000000e+09, \n    \"prefetch_bucket_size\": 5.000000e+07, \n    \"param_persistence_threshold\": 1.000000e+05, \n    \"max_live_parameters\": 1.000000e+09, \n    \"max_reuse_distance\": 1.000000e+09, \n    \"gather_fp16_weights_on_model_save\": false, \n    \"ignore_unused_parameters\": true, \n    \"round_robin_gradients\": false, \n    \"legacy_stage1\": false\n}\n[2022-02-11 01:44:44,090] [INFO] [config.py:1062:print]   zero_enabled ................. False\n[2022-02-11 01:44:44,091] [INFO] [config.py:1062:print]   zero_optimization_stage ...... 0\n[2022-02-11 01:44:44,091] [INFO] [config.py:1064:print]   json = {\n    \"train_batch_size\": 16, \n    \"steps_per_print\": 2.000000e+03, \n    \"optimizer\": {\n        \"type\": \"Adam\", \n        \"params\": {\n            \"lr\": 0.001, \n            \"betas\": [0.8, 0.999], \n            \"eps\": 1e-08, \n            \"weight_decay\": 3e-07\n        }\n    }, \n    \"scheduler\": {\n        \"type\": \"WarmupLR\", \n        \"params\": {\n            \"warmup_min_lr\": 0, \n            \"warmup_max_lr\": 0.001, \n            \"warmup_num_steps\": 1000\n        }\n    }, \n    \"gradient_clipping\": 1.0, \n    \"prescale_gradients\": false, \n    \"fp16\": {\n        \"enabled\": true, \n        \"fp16_master_weights_and_grads\": false, \n        \"loss_scale\": 0, \n        \"loss_scale_window\": 500, \n        \"hysteresis\": 2, \n        \"min_loss_scale\": 1, \n        \"initial_scale_power\": 15\n    }, \n    \"wall_clock_breakdown\": false, \n    \"zero_optimization\": {\n        \"stage\": 0, \n        \"allgather_partitions\": true, \n        \"reduce_scatter\": true, \n        \"allgather_bucket_size\": 5.000000e+07, \n        \"reduce_bucket_size\": 5.000000e+07, \n        \"overlap_comm\": true, \n        \"contiguous_gradients\": true, \n        \"cpu_offload\": false\n    }\n}\nUsing /home/azureuser/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\nEmitting ninja build file /home/azureuser/.cache/torch_extensions/py38_cu111/utils/build.ninja...\nBuilding extension module utils...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module utils...\nTime to load utils op: 0.34139180183410645 seconds\nfp16=True\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543883382
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543883537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_engine.world_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543883662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_engine.num_experts"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "8"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644543883796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(args.epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(model_engine.local_rank), data[1].to(\n",
        "            model_engine.local_rank)\n",
        "        if fp16:\n",
        "            inputs = inputs.half()\n",
        "        outputs, gate_loss = model_engine(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % args.log_interval == (args.log_interval - 1):  # print every log_interval mini-batches\n",
        "            print('training loss [%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / args.log_interval))\n",
        "            mlflow.log_metric(\"train loss\", running_loss / args.log_interval)\n",
        "            mlflow.log_metric(\"gate loss\", gate_loss.detach().cpu().numpy() / args.log_interval)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-11 01:45:02,473] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 453\n[2022-02-11 01:45:02,475] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 32768 to 16384.0\n[2022-02-11 01:45:02,477] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768, reducing to 16384.0\ntraining loss [1,   500] loss: 2.286\n[2022-02-11 01:45:09,417] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:09,418] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\ntraining loss [1,  1000] loss: 2.271\n[2022-02-11 01:45:16,006] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:16,008] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n[2022-02-11 01:45:16,019] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 1455\n[2022-02-11 01:45:16,020] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:16,020] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\ntraining loss [1,  1500] loss: 2.254\n[2022-02-11 01:45:22,516] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:22,517] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n[2022-02-11 01:45:22,528] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 1957\n[2022-02-11 01:45:22,528] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:22,529] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n[2022-02-11 01:45:23,038] [INFO] [logging.py:69:log_dist] [Rank 0] step=2000, skipped=3, lr=[0.001], mom=[[0.8, 0.999]]\n[2022-02-11 01:45:23,038] [INFO] [timer.py:181:stop] 0/2000, SamplesPerSec=1308.4136589813688\ntraining loss [1,  2000] loss: 2.251\n[2022-02-11 01:45:29,103] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:29,105] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n[2022-02-11 01:45:29,116] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 2459\n[2022-02-11 01:45:29,116] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:29,117] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\ntraining loss [1,  2500] loss: 2.253\n[2022-02-11 01:45:31,444] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 2621\n[2022-02-11 01:45:31,445] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0\n[2022-02-11 01:45:31,446] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\ntraining loss [1,  3000] loss: 2.241\n[2022-02-11 01:45:37,792] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:37,793] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 16384.0 to 32768.0\n[2022-02-11 01:45:43,999] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:44,002] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n[2022-02-11 01:45:44,013] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 3623\n[2022-02-11 01:45:44,014] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:44,015] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\ntraining loss [2,   500] loss: 2.246\n[2022-02-11 01:45:48,900] [INFO] [logging.py:69:log_dist] [Rank 0] step=4000, skipped=6, lr=[0.001], mom=[[0.8, 0.999]]\n[2022-02-11 01:45:48,901] [INFO] [timer.py:181:stop] 0/4000, SamplesPerSec=1315.673694873533\n[2022-02-11 01:45:50,419] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:50,420] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\ntraining loss [2,  1000] loss: 2.235\n[2022-02-11 01:45:50,906] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 4125\n[2022-02-11 01:45:50,906] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:50,907] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\ntraining loss [2,  1500] loss: 2.236\n[2022-02-11 01:45:57,492] [INFO] [fused_optimizer.py:349:_update_scale] No Grad overflow for 500 iterations\n[2022-02-11 01:45:57,493] [INFO] [fused_optimizer.py:351:_update_scale] Increasing dynamic loss scale from 32768.0 to 65536.0\n[2022-02-11 01:45:57,504] [INFO] [fused_optimizer.py:339:_update_scale] \nGrad overflow on iteration 4627\n[2022-02-11 01:45:57,505] [INFO] [fused_optimizer.py:340:_update_scale] Reducing dynamic loss scale from 65536.0 to 32768.0\n[2022-02-11 01:45:57,505] [INFO] [logging.py:69:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644536538940
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if fp16:\n",
        "            images = images.half()\n",
        "        outputs,gate_loss = net(images.to(model_engine.local_rank))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(\n",
        "            model_engine.local_rank)).sum().item()\n",
        "mlflow.log_metric(\"test accuracy\", 100*correct/total)\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' %\n",
        "      (100 * correct / total))\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if fp16:\n",
        "            images = images.half()\n",
        "        outputs,gate_loss = net(images.to(model_engine.local_rank))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels.to(model_engine.local_rank)).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' %\n",
        "          (classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644535172320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pt_tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "azureml_py38_pt_tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}