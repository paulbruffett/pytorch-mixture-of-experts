{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate azureml_py38_PT_TF\n",
        "pip install deepspeed\n",
        "pip install mpi4py\n",
        "pip install ipywidgets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: deepspeed in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.5.10)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.10.1)\nRequirement already satisfied: py-cpuinfo in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (8.0.0)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.21.5)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (4.62.3)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (21.3)\nRequirement already satisfied: ninja in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.10.2.3)\nRequirement already satisfied: hjson in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (3.0.2)\nRequirement already satisfied: psutil in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (5.9.0)\nRequirement already satisfied: triton==1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from deepspeed) (1.0.0)\nRequirement already satisfied: typing_extensions in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torch->deepspeed) (4.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging->deepspeed) (3.0.6)\nRequirement already satisfied: mpi4py in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (3.1.3)\nRequirement already satisfied: ipywidgets in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (7.6.5)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\nRequirement already satisfied: nbformat>=4.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (1.0.2)\nRequirement already satisfied: ipykernel>=4.5.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (6.6.0)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (3.5.2)\nRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipywidgets) (7.30.1)\nRequirement already satisfied: jupyter-core in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\nRequirement already satisfied: debugpy<2.0,>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\nRequirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\nRequirement already satisfied: jupyter-client<8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.0)\nRequirement already satisfied: tornado<7.0,>=4.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\nRequirement already satisfied: notebook>=4.4.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\nRequirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\nRequirement already satisfied: backcall in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (50.3.0.post20201006)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.24)\nRequirement already satisfied: pygments in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.11.0)\nRequirement already satisfied: pickleshare in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\nRequirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.1)\nRequirement already satisfied: decorator in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (5.1.0)\nRequirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\nRequirement already satisfied: entrypoints in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\nRequirement already satisfied: pyzmq>=13 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.4)\nRequirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\nRequirement already satisfied: Send2Trash>=1.8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\nRequirement already satisfied: argon2-cffi in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\nRequirement already satisfied: terminado>=0.8.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\nRequirement already satisfied: nbconvert in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.1)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\nRequirement already satisfied: prometheus-client in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.0)\nRequirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\nRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\nRequirement already satisfied: argon2-cffi-bindings in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\nRequirement already satisfied: mistune<2,>=0.8.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\nRequirement already satisfied: pandocfilters>=1.4.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\nRequirement already satisfied: defusedxml in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.10)\nRequirement already satisfied: testpath in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\nRequirement already satisfied: bleach in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\nRequirement already satisfied: jupyterlab-pygments in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\nRequirement already satisfied: cffi>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\nRequirement already satisfied: webencodings in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.6)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup an experiment to log metrics\n",
        "from azureml.core import Workspace\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "\n",
        "mlflow.create_experiment(\"deepspeed-notebook\")\n",
        "mlflow.set_experiment(\"deepspeed-notebook\")\n",
        "mlflow_run = mlflow.start_run()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809540532
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_config = {\n",
        "  \"train_batch_size\": 16,\n",
        "  \"steps_per_print\": 2000,\n",
        "  \"optimizer\": {\n",
        "    \"type\": \"Adam\",\n",
        "    \"params\": {\n",
        "      \"lr\": 0.001,\n",
        "      \"betas\": [\n",
        "        0.8,\n",
        "        0.999\n",
        "      ],\n",
        "      \"eps\": 1e-8,\n",
        "      \"weight_decay\": 3e-7\n",
        "    }\n",
        "  },\n",
        "  \"scheduler\": {\n",
        "    \"type\": \"WarmupLR\",\n",
        "    \"params\": {\n",
        "      \"warmup_min_lr\": 0,\n",
        "      \"warmup_max_lr\": 0.001,\n",
        "      \"warmup_num_steps\": 1000\n",
        "    }\n",
        "  },\n",
        "  \"gradient_clipping\": 1.0,\n",
        "  \"prescale_gradients\": False,\n",
        "  \"fp16\": {\n",
        "      \"enabled\": True,\n",
        "      \"fp16_master_weights_and_grads\": False,\n",
        "      \"loss_scale\": 0,\n",
        "      \"loss_scale_window\": 500,\n",
        "      \"hysteresis\": 2,\n",
        "      \"min_loss_scale\": 1,\n",
        "      \"initial_scale_power\": 15\n",
        "  },\n",
        "  \"wall_clock_breakdown\": False,\n",
        "  \"zero_optimization\": {\n",
        "      \"stage\": 0,\n",
        "      \"allgather_partitions\": True,\n",
        "      \"reduce_scatter\": True,\n",
        "      \"allgather_bucket_size\": 50000000,\n",
        "      \"reduce_bucket_size\": 50000000,\n",
        "      \"overlap_comm\": True,\n",
        "      \"contiguous_gradients\": True,\n",
        "      \"cpu_offload\": False\n",
        "  }\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809540688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import deepspeed\n",
        "\n",
        "#initialize deepspeed to get process rank below\n",
        "deepspeed.init_distributed()\n",
        "\n",
        "\n",
        "#load and prepare the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "if torch.distributed.get_rank() != 0:\n",
        "    # might be downloading cifar data, let rank 0 download first\n",
        "    torch.distributed.barrier()\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        train=True,\n",
        "                                        download=True,\n",
        "                                        transform=transform)\n",
        "\n",
        "if torch.distributed.get_rank() == 0:\n",
        "    # cifar data is downloaded, indicate other ranks can proceed\n",
        "    torch.distributed.barrier()\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size=ds_config['train_batch_size'],\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=ds_config['train_batch_size'],\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-14 03:32:22,441] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...\n[2022-02-14 03:32:22,836] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.0.0.5, master_port=29500\n[2022-02-14 03:32:22,838] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl\nFiles already downloaded and verified\nFiles already downloaded and verified\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1644809573551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser(description='CIFAR')\n",
        "\n",
        "parser.add_argument('--with_cuda',\n",
        "                    default=True,\n",
        "                    action='store_true',\n",
        "                    help='use CPU in case there\\'s no GPU support')\n",
        "\n",
        "parser.add_argument('--use_ema',\n",
        "                    default=False,\n",
        "                    action='store_true',\n",
        "                    help='whether use exponential moving average')\n",
        "\n",
        "parser.add_argument('-e',\n",
        "                    '--epochs',\n",
        "                    default=1,\n",
        "                    type=int,\n",
        "                    help='number of total epochs (default: 30)')\n",
        "\n",
        "parser.add_argument('--local_rank',\n",
        "                    type=int,\n",
        "                    default=-1,\n",
        "                    help='local rank passed from distributed launcher')\n",
        "\n",
        "parser.add_argument('--log-interval',\n",
        "                    type=int,\n",
        "                    default=500,\n",
        "                    help=\"output logging information at a given interval\")\n",
        "\n",
        "\n",
        "parser.add_argument('--ep-world-size',\n",
        "                    default=40,\n",
        "                    type=int,\n",
        "                    help='(moe) expert parallel world size')\n",
        "\n",
        "parser.add_argument('--num-experts',\n",
        "                    default=40,\n",
        "                    type=int,\n",
        "                    help='(moe) number of total experts')\n",
        "\n",
        "parser.add_argument('--top-k',\n",
        "                    default=1,\n",
        "                    type=int,\n",
        "                    help='(moe) gating top 1 and 2 supported')\n",
        "\n",
        "parser.add_argument('--min-capacity',\n",
        "                    default=0,\n",
        "                    type=int,\n",
        "                    help='(moe) minimum capacity of an expert regardless of the capacity_factor')\n",
        "\n",
        "parser.add_argument(\n",
        "                '--noisy-gate-policy',\n",
        "                default=None,\n",
        "                type=str,\n",
        "                help='(moe) noisy gating (only supported with top-1). Valid values are None, RSample, and Jitter')\n",
        "\n",
        "parser.add_argument(\n",
        "                '--moe-param-group',\n",
        "                default=False,\n",
        "                action='store_true',\n",
        "                help='(moe) create separate moe param groups, required when using ZeRO w. MoE')\n",
        "\n",
        "# Include DeepSpeed configuration arguments\n",
        "parser = deepspeed.add_config_arguments(parser)\n",
        "\n",
        "args = parser.parse_args(\"\")"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809573731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.log_param(\"ema\", args.use_ema)\n",
        "mlflow.log_param(\"epochs\", args.epochs)\n",
        "mlflow.log_param(\"experts\", args.num_experts)\n",
        "mlflow.log_param(\"noisy gate\", args.noisy_gate_policy)\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809574320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deepspeed.utils.groups.initialize(ep_size=args.ep_world_size)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-14 03:32:55,018] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed groups\n[2022-02-14 03:32:55,020] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1\n[2022-02-14 03:32:55,022] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 40\n[2022-02-14 03:32:55,025] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]\n[2022-02-14 03:32:55,025] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [0]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809574504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in enumerate(trainloader):\n",
        "    break\n",
        "channels = i[1][0].shape[1]\n",
        "height = i[1][0].shape[-1]\n",
        "hidden_size = channels * height * height\n",
        "i[1][0].shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "torch.Size([16, 3, 32, 32])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809574709
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,stride=1,kernel_size=3,padding=1,bias=False):\n",
        "        super(ResidualBlock,self).__init__()\n",
        "        self.cnn1 =nn.Sequential(\n",
        "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.cnn2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels,out_channels,kernel_size,1,padding,bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential()\n",
        "            \n",
        "    def forward(self,x):\n",
        "        residual = x\n",
        "        x = self.cnn1(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += self.shortcut(residual)\n",
        "        x = nn.ReLU(True)(x)\n",
        "        return x\n",
        "\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(self, hidden_size, channels, height):\n",
        "        super(ResNet34,self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.channels = channels\n",
        "        self.height = height\n",
        "        \n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3,64,kernel_size=2,stride=2,padding=3,bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        \n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.MaxPool2d(1,1),\n",
        "            ResidualBlock(64,64),\n",
        "            ResidualBlock(64,64,2)\n",
        "        )\n",
        "        \n",
        "        self.block3 = nn.Sequential(\n",
        "            ResidualBlock(64,128),\n",
        "            ResidualBlock(128,128,2)\n",
        "        )\n",
        "        \n",
        "        self.block4 = nn.Sequential(\n",
        "            ResidualBlock(128,256),\n",
        "            ResidualBlock(256,256,2)\n",
        "        )\n",
        "        self.block5 = nn.Sequential(\n",
        "            ResidualBlock(256,512),\n",
        "            ResidualBlock(512,512,2)\n",
        "        )\n",
        "        \n",
        "        self.avgpool = nn.AvgPool2d(2)\n",
        "\n",
        "        self.fc1 = nn.Linear(512,self.hidden_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = torch.reshape(x, (-1, self.channels, self.height, self.height))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809574896
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.resnet = ResNet34(hidden_size, channels, height)\n",
        "        self.moe = deepspeed.moe.layer.MoE(\n",
        "            hidden_size=hidden_size,\n",
        "            expert=self.resnet,\n",
        "            num_experts=args.num_experts,\n",
        "            k=args.top_k,\n",
        "            min_capacity=args.min_capacity,\n",
        "            noisy_gate_policy=args.noisy_gate_policy)\n",
        "        self.fc = nn.Linear(hidden_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(ds_config['train_batch_size'], hidden_size)\n",
        "        x, gate_loss, _ = self.moe(x)\n",
        "        x = self.fc(x)\n",
        "        return x , gate_loss\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809575094
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "\n",
        "\n",
        "def create_moe_param_groups(model):\n",
        "    from deepspeed.moe.utils import split_params_into_different_moe_groups_for_optimizer\n",
        "\n",
        "    parameters = {'params': model.parameters(), 'name': 'parameters'}\n",
        "\n",
        "    return split_params_into_different_moe_groups_for_optimizer(parameters)\n",
        "\n",
        "\n",
        "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "if args.moe_param_group:\n",
        "    parameters = create_moe_param_groups(net)\n",
        "\n",
        "# Initialize DeepSpeed to use the following features\n",
        "# 1) Distributed model\n",
        "# 2) Distributed data loader\n",
        "# 3) DeepSpeed optimizer\n",
        "model_engine, optimizer, trainloader, __ = deepspeed.initialize(\n",
        "    args=args, model=net, model_parameters=parameters, training_data=trainset, config=ds_config)\n",
        "\n",
        "fp16 = model_engine.fp16_enabled()\n",
        "print(f'fp16={fp16}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[2022-02-14 03:32:55,648] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 40 | num_local_experts: 40 | expert_parallel_size: 1\n[2022-02-14 03:32:56,850] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.5.10, git-hash=unknown, git-branch=unknown\n[2022-02-14 03:32:57,737] [INFO] [engine.py:275:__init__] DeepSpeed Flops Profiler Enabled: False\nInstalled CUDA version 11.2 does not match the version torch was compiled with 11.1 but since the APIs are compatible, accepting this combination\nUsing /home/azureuser/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\nDetected CUDA files, patching ldflags\nEmitting ninja build file /home/azureuser/.cache/torch_extensions/py38_cu111/fused_adam/build.ninja...\nBuilding extension module fused_adam...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module fused_adam...\nTime to load fused_adam op: 0.34184861183166504 seconds\n[2022-02-14 03:32:58,675] [INFO] [engine.py:1105:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer\n[2022-02-14 03:33:00,145] [INFO] [engine.py:1113:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam\n[2022-02-14 03:33:00,147] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale\n[2022-02-14 03:33:00,810] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam\n[2022-02-14 03:33:00,812] [INFO] [engine.py:795:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n[2022-02-14 03:33:00,812] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f2d1c0bfe80>\n[2022-02-14 03:33:00,813] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[[0.8, 0.999]]\n[2022-02-14 03:33:00,824] [INFO] [config.py:1058:print] DeepSpeedEngine configuration:\n[2022-02-14 03:33:00,825] [INFO] [config.py:1062:print]   activation_checkpointing_config  {\n    \"partition_activations\": false, \n    \"contiguous_memory_optimization\": false, \n    \"cpu_checkpointing\": false, \n    \"number_checkpoints\": null, \n    \"synchronize_checkpoint_boundary\": false, \n    \"profile\": false\n}\n[2022-02-14 03:33:00,826] [INFO] [config.py:1062:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n[2022-02-14 03:33:00,826] [INFO] [config.py:1062:print]   amp_enabled .................. False\n[2022-02-14 03:33:00,827] [INFO] [config.py:1062:print]   amp_params ................... False\n[2022-02-14 03:33:00,827] [INFO] [config.py:1062:print]   autotuning_config ............ {\n    \"enabled\": false, \n    \"start_step\": null, \n    \"end_step\": null, \n    \"metric_path\": null, \n    \"arg_mappings\": null, \n    \"metric\": \"throughput\", \n    \"model_info\": null, \n    \"results_dir\": null, \n    \"exps_dir\": null, \n    \"overwrite\": true, \n    \"fast\": true, \n    \"start_profile_step\": 3, \n    \"end_profile_step\": 5, \n    \"tuner_type\": \"gridsearch\", \n    \"tuner_early_stopping\": 5, \n    \"tuner_num_trials\": 50, \n    \"model_info_path\": null, \n    \"mp_size\": 1, \n    \"max_train_batch_size\": null, \n    \"min_train_batch_size\": 1, \n    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n    \"min_train_micro_batch_size_per_gpu\": 1, \n    \"num_tuning_micro_batch_sizes\": 3\n}\n[2022-02-14 03:33:00,828] [INFO] [config.py:1062:print]   bfloat16_enabled ............. False\n[2022-02-14 03:33:00,828] [INFO] [config.py:1062:print]   checkpoint_tag_validation_enabled  True\n[2022-02-14 03:33:00,829] [INFO] [config.py:1062:print]   checkpoint_tag_validation_fail  False\n[2022-02-14 03:33:00,829] [INFO] [config.py:1062:print]   communication_data_type ...... None\n[2022-02-14 03:33:00,830] [INFO] [config.py:1062:print]   curriculum_enabled ........... False\n[2022-02-14 03:33:00,831] [INFO] [config.py:1062:print]   curriculum_params ............ False\n[2022-02-14 03:33:00,832] [INFO] [config.py:1062:print]   dataloader_drop_last ......... False\n[2022-02-14 03:33:00,832] [INFO] [config.py:1062:print]   disable_allgather ............ False\n[2022-02-14 03:33:00,833] [INFO] [config.py:1062:print]   dump_state ................... False\n[2022-02-14 03:33:00,833] [INFO] [config.py:1062:print]   dynamic_loss_scale_args ...... {'init_scale': 32768, 'scale_window': 500, 'delayed_shift': 2, 'min_scale': 1}\n[2022-02-14 03:33:00,834] [INFO] [config.py:1062:print]   eigenvalue_enabled ........... False\n[2022-02-14 03:33:00,834] [INFO] [config.py:1062:print]   eigenvalue_gas_boundary_resolution  1\n[2022-02-14 03:33:00,835] [INFO] [config.py:1062:print]   eigenvalue_layer_name ........ bert.encoder.layer\n[2022-02-14 03:33:00,835] [INFO] [config.py:1062:print]   eigenvalue_layer_num ......... 0\n[2022-02-14 03:33:00,836] [INFO] [config.py:1062:print]   eigenvalue_max_iter .......... 100\n[2022-02-14 03:33:00,836] [INFO] [config.py:1062:print]   eigenvalue_stability ......... 1e-06\n[2022-02-14 03:33:00,837] [INFO] [config.py:1062:print]   eigenvalue_tol ............... 0.01\n[2022-02-14 03:33:00,837] [INFO] [config.py:1062:print]   eigenvalue_verbose ........... False\n[2022-02-14 03:33:00,838] [INFO] [config.py:1062:print]   elasticity_enabled ........... False\n[2022-02-14 03:33:00,838] [INFO] [config.py:1062:print]   flops_profiler_config ........ {\n    \"enabled\": false, \n    \"profile_step\": 1, \n    \"module_depth\": -1, \n    \"top_modules\": 1, \n    \"detailed\": true, \n    \"output_file\": null\n}\n[2022-02-14 03:33:00,839] [INFO] [config.py:1062:print]   fp16_enabled ................. True\n[2022-02-14 03:33:00,839] [INFO] [config.py:1062:print]   fp16_master_weights_and_gradients  False\n[2022-02-14 03:33:00,840] [INFO] [config.py:1062:print]   fp16_mixed_quantize .......... False\n[2022-02-14 03:33:00,840] [INFO] [config.py:1062:print]   global_rank .................. 0\n[2022-02-14 03:33:00,844] [INFO] [config.py:1062:print]   gradient_accumulation_steps .. 1\n[2022-02-14 03:33:00,844] [INFO] [config.py:1062:print]   gradient_clipping ............ 1.0\n[2022-02-14 03:33:00,845] [INFO] [config.py:1062:print]   gradient_predivide_factor .... 1.0\n[2022-02-14 03:33:00,845] [INFO] [config.py:1062:print]   initial_dynamic_scale ........ 32768\n[2022-02-14 03:33:00,846] [INFO] [config.py:1062:print]   loss_scale ................... 0\n[2022-02-14 03:33:00,846] [INFO] [config.py:1062:print]   memory_breakdown ............. False\n[2022-02-14 03:33:00,847] [INFO] [config.py:1062:print]   optimizer_legacy_fusion ...... False\n[2022-02-14 03:33:00,847] [INFO] [config.py:1062:print]   optimizer_name ............... adam\n[2022-02-14 03:33:00,848] [INFO] [config.py:1062:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.8, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n[2022-02-14 03:33:00,848] [INFO] [config.py:1062:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n[2022-02-14 03:33:00,849] [INFO] [config.py:1062:print]   pld_enabled .................. False\n[2022-02-14 03:33:00,850] [INFO] [config.py:1062:print]   pld_params ................... False\n[2022-02-14 03:33:00,850] [INFO] [config.py:1062:print]   prescale_gradients ........... False\n[2022-02-14 03:33:00,851] [INFO] [config.py:1062:print]   quantize_change_rate ......... 0.001\n[2022-02-14 03:33:00,851] [INFO] [config.py:1062:print]   quantize_groups .............. 1\n[2022-02-14 03:33:00,852] [INFO] [config.py:1062:print]   quantize_offset .............. 1000\n[2022-02-14 03:33:00,853] [INFO] [config.py:1062:print]   quantize_period .............. 1000\n[2022-02-14 03:33:00,853] [INFO] [config.py:1062:print]   quantize_rounding ............ 0\n[2022-02-14 03:33:00,854] [INFO] [config.py:1062:print]   quantize_start_bits .......... 16\n[2022-02-14 03:33:00,855] [INFO] [config.py:1062:print]   quantize_target_bits ......... 8\n[2022-02-14 03:33:00,856] [INFO] [config.py:1062:print]   quantize_training_enabled .... False\n[2022-02-14 03:33:00,856] [INFO] [config.py:1062:print]   quantize_type ................ 0\n[2022-02-14 03:33:00,857] [INFO] [config.py:1062:print]   quantize_verbose ............. False\n[2022-02-14 03:33:00,857] [INFO] [config.py:1062:print]   scheduler_name ............... WarmupLR\n[2022-02-14 03:33:00,858] [INFO] [config.py:1062:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 0.001, 'warmup_num_steps': 1000}\n[2022-02-14 03:33:00,858] [INFO] [config.py:1062:print]   sparse_attention ............. None\n[2022-02-14 03:33:00,859] [INFO] [config.py:1062:print]   sparse_gradients_enabled ..... False\n[2022-02-14 03:33:00,859] [INFO] [config.py:1062:print]   steps_per_print .............. 2000\n[2022-02-14 03:33:00,860] [INFO] [config.py:1062:print]   tensorboard_enabled .......... False\n[2022-02-14 03:33:00,860] [INFO] [config.py:1062:print]   tensorboard_job_name ......... DeepSpeedJobName\n[2022-02-14 03:33:00,861] [INFO] [config.py:1062:print]   tensorboard_output_path ...... \n[2022-02-14 03:33:00,861] [INFO] [config.py:1062:print]   train_batch_size ............. 16\n[2022-02-14 03:33:00,861] [INFO] [config.py:1062:print]   train_micro_batch_size_per_gpu  16\n[2022-02-14 03:33:00,862] [INFO] [config.py:1062:print]   use_quantizer_kernel ......... False\n[2022-02-14 03:33:00,862] [INFO] [config.py:1062:print]   wall_clock_breakdown ......... False\n[2022-02-14 03:33:00,863] [INFO] [config.py:1062:print]   world_size ................... 1\n[2022-02-14 03:33:00,863] [INFO] [config.py:1062:print]   zero_allow_untested_optimizer  False\n[2022-02-14 03:33:00,864] [INFO] [config.py:1062:print]   zero_config .................. {\n    \"stage\": 0, \n    \"contiguous_gradients\": true, \n    \"reduce_scatter\": true, \n    \"reduce_bucket_size\": 5.000000e+07, \n    \"allgather_partitions\": true, \n    \"allgather_bucket_size\": 5.000000e+07, \n    \"overlap_comm\": true, \n    \"load_from_fp32_weights\": true, \n    \"elastic_checkpoint\": false, \n    \"offload_param\": null, \n    \"offload_optimizer\": null, \n    \"sub_group_size\": 1.000000e+09, \n    \"prefetch_bucket_size\": 5.000000e+07, \n    \"param_persistence_threshold\": 1.000000e+05, \n    \"max_live_parameters\": 1.000000e+09, \n    \"max_reuse_distance\": 1.000000e+09, \n    \"gather_fp16_weights_on_model_save\": false, \n    \"ignore_unused_parameters\": true, \n    \"round_robin_gradients\": false, \n    \"legacy_stage1\": false\n}\n[2022-02-14 03:33:00,864] [INFO] [config.py:1062:print]   zero_enabled ................. False\n[2022-02-14 03:33:00,865] [INFO] [config.py:1062:print]   zero_optimization_stage ...... 0\n[2022-02-14 03:33:00,865] [INFO] [config.py:1064:print]   json = {\n    \"train_batch_size\": 16, \n    \"steps_per_print\": 2.000000e+03, \n    \"optimizer\": {\n        \"type\": \"Adam\", \n        \"params\": {\n            \"lr\": 0.001, \n            \"betas\": [0.8, 0.999], \n            \"eps\": 1e-08, \n            \"weight_decay\": 3e-07\n        }\n    }, \n    \"scheduler\": {\n        \"type\": \"WarmupLR\", \n        \"params\": {\n            \"warmup_min_lr\": 0, \n            \"warmup_max_lr\": 0.001, \n            \"warmup_num_steps\": 1000\n        }\n    }, \n    \"gradient_clipping\": 1.0, \n    \"prescale_gradients\": false, \n    \"fp16\": {\n        \"enabled\": true, \n        \"fp16_master_weights_and_grads\": false, \n        \"loss_scale\": 0, \n        \"loss_scale_window\": 500, \n        \"hysteresis\": 2, \n        \"min_loss_scale\": 1, \n        \"initial_scale_power\": 15\n    }, \n    \"wall_clock_breakdown\": false, \n    \"zero_optimization\": {\n        \"stage\": 0, \n        \"allgather_partitions\": true, \n        \"reduce_scatter\": true, \n        \"allgather_bucket_size\": 5.000000e+07, \n        \"reduce_bucket_size\": 5.000000e+07, \n        \"overlap_comm\": true, \n        \"contiguous_gradients\": true, \n        \"cpu_offload\": false\n    }\n}\nUsing /home/azureuser/.cache/torch_extensions/py38_cu111 as PyTorch extensions root...\nEmitting ninja build file /home/azureuser/.cache/torch_extensions/py38_cu111/utils/build.ninja...\nBuilding extension module utils...\nAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\nLoading extension module utils...\nTime to load utils op: 0.33937573432922363 seconds\nfp16=True\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809580515
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "4"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809580653
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_engine.world_size"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809580971
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_engine.num_experts"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "40"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644809581286
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "for epoch in range(args.epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(model_engine.local_rank), data[1].to(\n",
        "            model_engine.local_rank)\n",
        "        if fp16:\n",
        "            inputs = inputs.half()\n",
        "        outputs, gate_loss = model_engine(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        model_engine.backward(loss)\n",
        "        model_engine.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % args.log_interval == (args.log_interval - 1):  # print every log_interval mini-batches\n",
        "            print('training loss [%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / args.log_interval))\n",
        "            mlflow.log_metric(\"train loss\", running_loss / args.log_interval)\n",
        "            mlflow.log_metric(\"gate loss\", gate_loss.detach().cpu().numpy() / args.log_interval)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 11.17 GiB total capacity; 10.03 GiB already allocated; 645.88 MiB free; 10.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f58f1f1ad3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, lr_kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_model_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_eigenvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_model_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtput_timer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/deepspeed/runtime/engine.py\u001b[0m in \u001b[0;36m_take_model_step\u001b[0;34m(self, lr_kwargs, block_eigenvalue)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                                 \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                                 mpu=self.mpu)\n\u001b[0;32m-> 1799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_global_grad_norm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/deepspeed/runtime/fp16/fused_optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             grads_groups_flat.append(\n\u001b[0;32m--> 245\u001b[0;31m                 _flatten_dense_tensors([\n\u001b[0m\u001b[1;32m    246\u001b[0m                     torch.zeros(p.size(),\n\u001b[1;32m    247\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_flatten_dense_tensors\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mcontiguous\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0mD\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dense_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 GiB (GPU 0; 11.17 GiB total capacity; 10.03 GiB already allocated; 645.88 MiB free; 10.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644807354857
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if fp16:\n",
        "            images = images.half()\n",
        "        outputs,gate_loss = net(images.to(model_engine.local_rank))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(\n",
        "            model_engine.local_rank)).sum().item()\n",
        "mlflow.log_metric(\"test accuracy\", 100*correct/total)\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' %\n",
        "      (100 * correct / total))\n",
        "\n",
        "########################################################################\n",
        "# That looks way better than chance, which is 10% accuracy (randomly picking\n",
        "# a class out of 10 classes).\n",
        "# Seems like the network learnt something.\n",
        "#\n",
        "# Hmmm, what are the classes that performed well, and the classes that did\n",
        "# not perform well:\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if fp16:\n",
        "            images = images.half()\n",
        "        outputs,gate_loss = net(images.to(model_engine.local_rank))\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels.to(model_engine.local_rank)).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' %\n",
        "          (trainset.classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644807875222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1644807875901
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "azureml_py38_pt_tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "azureml_py38_pt_tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}